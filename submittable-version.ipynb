{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Import tools and libs"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# We'll need numpy for some mathematical operations\nimport numpy as np\n\n# matplotlib for displaying the output\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# and IPython.display for audio output\nimport IPython.display\n\n# Librosa for audio\nimport librosa\n# And the display module for visualization\nimport librosa.display\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating bird code dict and inverted dict"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n    'aldfly': 0, 'ameavo': 1, 'amebit': 2, 'amecro': 3, 'amegfi': 4,\n    'amekes': 5, 'amepip': 6, 'amered': 7, 'amerob': 8, 'amewig': 9,\n    'amewoo': 10, 'amtspa': 11, 'annhum': 12, 'astfly': 13, 'baisan': 14,\n    'baleag': 15, 'balori': 16, 'banswa': 17, 'barswa': 18, 'bawwar': 19,\n    'belkin1': 20, 'belspa2': 21, 'bewwre': 22, 'bkbcuc': 23, 'bkbmag1': 24,\n    'bkbwar': 25, 'bkcchi': 26, 'bkchum': 27, 'bkhgro': 28, 'bkpwar': 29,\n    'bktspa': 30, 'blkpho': 31, 'blugrb1': 32, 'blujay': 33, 'bnhcow': 34,\n    'boboli': 35, 'bongul': 36, 'brdowl': 37, 'brebla': 38, 'brespa': 39,\n    'brncre': 40, 'brnthr': 41, 'brthum': 42, 'brwhaw': 43, 'btbwar': 44,\n    'btnwar': 45, 'btywar': 46, 'buffle': 47, 'buggna': 48, 'buhvir': 49,\n    'bulori': 50, 'bushti': 51, 'buwtea': 52, 'buwwar': 53, 'cacwre': 54,\n    'calgul': 55, 'calqua': 56, 'camwar': 57, 'cangoo': 58, 'canwar': 59,\n    'canwre': 60, 'carwre': 61, 'casfin': 62, 'caster1': 63, 'casvir': 64,\n    'cedwax': 65, 'chispa': 66, 'chiswi': 67, 'chswar': 68, 'chukar': 69,\n    'clanut': 70, 'cliswa': 71, 'comgol': 72, 'comgra': 73, 'comloo': 74,\n    'commer': 75, 'comnig': 76, 'comrav': 77, 'comred': 78, 'comter': 79,\n    'comyel': 80, 'coohaw': 81, 'coshum': 82, 'cowscj1': 83, 'daejun': 84,\n    'doccor': 85, 'dowwoo': 86, 'dusfly': 87, 'eargre': 88, 'easblu': 89,\n    'easkin': 90, 'easmea': 91, 'easpho': 92, 'eastow': 93, 'eawpew': 94,\n    'eucdov': 95, 'eursta': 96, 'evegro': 97, 'fiespa': 98, 'fiscro': 99,\n    'foxspa': 100, 'gadwal': 101, 'gcrfin': 102, 'gnttow': 103, 'gnwtea': 104,\n    'gockin': 105, 'gocspa': 106, 'goleag': 107, 'grbher3': 108, 'grcfly': 109,\n    'greegr': 110, 'greroa': 111, 'greyel': 112, 'grhowl': 113, 'grnher': 114,\n    'grtgra': 115, 'grycat': 116, 'gryfly': 117, 'haiwoo': 118, 'hamfly': 119,\n    'hergul': 120, 'herthr': 121, 'hoomer': 122, 'hoowar': 123, 'horgre': 124,\n    'horlar': 125, 'houfin': 126, 'houspa': 127, 'houwre': 128, 'indbun': 129,\n    'juntit1': 130, 'killde': 131, 'labwoo': 132, 'larspa': 133, 'lazbun': 134,\n    'leabit': 135, 'leafly': 136, 'leasan': 137, 'lecthr': 138, 'lesgol': 139,\n    'lesnig': 140, 'lesyel': 141, 'lewwoo': 142, 'linspa': 143, 'lobcur': 144,\n    'lobdow': 145, 'logshr': 146, 'lotduc': 147, 'louwat': 148, 'macwar': 149,\n    'magwar': 150, 'mallar3': 151, 'marwre': 152, 'merlin': 153, 'moublu': 154,\n    'mouchi': 155, 'moudov': 156, 'norcar': 157, 'norfli': 158, 'norhar2': 159,\n    'normoc': 160, 'norpar': 161, 'norpin': 162, 'norsho': 163, 'norwat': 164,\n    'nrwswa': 165, 'nutwoo': 166, 'olsfly': 167, 'orcwar': 168, 'osprey': 169,\n    'ovenbi1': 170, 'palwar': 171, 'pasfly': 172, 'pecsan': 173, 'perfal': 174,\n    'phaino': 175, 'pibgre': 176, 'pilwoo': 177, 'pingro': 178, 'pinjay': 179,\n    'pinsis': 180, 'pinwar': 181, 'plsvir': 182, 'prawar': 183, 'purfin': 184,\n    'pygnut': 185, 'rebmer': 186, 'rebnut': 187, 'rebsap': 188, 'rebwoo': 189,\n    'redcro': 190, 'redhea': 191, 'reevir1': 192, 'renpha': 193, 'reshaw': 194,\n    'rethaw': 195, 'rewbla': 196, 'ribgul': 197, 'rinduc': 198, 'robgro': 199,\n    'rocpig': 200, 'rocwre': 201, 'rthhum': 202, 'ruckin': 203, 'rudduc': 204,\n    'rufgro': 205, 'rufhum': 206, 'rusbla': 207, 'sagspa1': 208, 'sagthr': 209,\n    'savspa': 210, 'saypho': 211, 'scatan': 212, 'scoori': 213, 'semplo': 214,\n    'semsan': 215, 'sheowl': 216, 'shshaw': 217, 'snobun': 218, 'snogoo': 219,\n    'solsan': 220, 'sonspa': 221, 'sora': 222, 'sposan': 223, 'spotow': 224,\n    'stejay': 225, 'swahaw': 226, 'swaspa': 227, 'swathr': 228, 'treswa': 229,\n    'truswa': 230, 'tuftit': 231, 'tunswa': 232, 'veery': 233, 'vesspa': 234,\n    'vigswa': 235, 'warvir': 236, 'wesblu': 237, 'wesgre': 238, 'weskin': 239,\n    'wesmea': 240, 'wessan': 241, 'westan': 242, 'wewpew': 243, 'whbnut': 244,\n    'whcspa': 245, 'whfibi': 246, 'whtspa': 247, 'whtswi': 248, 'wilfly': 249,\n    'wilsni1': 250, 'wiltur': 251, 'winwre3': 252, 'wlswar': 253, 'wooduc': 254,\n    'wooscj2': 255, 'woothr': 256, 'y00475': 257, 'yebfly': 258, 'yebsap': 259,\n    'yehbla': 260, 'yelwar': 261, 'yerwar': 262, 'yetvir': 263\n}\n\nINV_BIRD_CODE = {v: k for k, v in BIRD_CODE.items()}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Wrapper class for Keras Sequential model"},{"metadata":{},"cell_type":"markdown","source":"The function baseline_model constructs a new model but this isn't actually necessary here; we want to load in a pre-trained model. getProbs(x) gives the prediction probabilities of x being each of the different birds (as in, it returns an array where for each bird species, the corresponding slot has the probability of x being of that species)."},{"metadata":{"trusted":true},"cell_type":"code","source":"class SeqModel():\n    def __init__(self, model_path):\n        self.model = keras.models.load_model('path/to/location')\n        # needs corresponding model.save('path/to/location') after being trained elsewhere\n        \n    def baseline_model(self):\n        # Construct model \n        model = Sequential()\n        model.add(Conv2D(filters=16, kernel_size=2, input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n        model.add(MaxPooling2D(pool_size=2))\n        model.add(Dropout(0.2))\n\n        model.add(Conv2D(filters=32, kernel_size=2, activation='relu'))\n        model.add(MaxPooling2D(pool_size=2))\n        model.add(Dropout(0.2))\n\n        model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n        model.add(MaxPooling2D(pool_size=2)) #Has a problem with this line (THE INPUT IMAGE WAS TOO SMALL)\n        model.add(Dropout(0.2))\n\n        model.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n        model.add(MaxPooling2D(pool_size=2)) ###\n        model.add(Dropout(0.2))\n        model.add(GlobalAveragePooling2D())\n\n        model.add(Dense(num_labels, activation='softmax'))\n        \n        # Compile the model\n        model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n        self.model = model\n        return model\n\n    def test(self, X, Y):\n        estimator = KerasClassifier(build_fn=self.model, epochs=200, batch_size=5, verbose=0)\n        # KFold Cross Validation\n        kfold = KFold(n_splits = 5, shuffle = True, random_state = seed)\n        # Try different values of splits e.g., 10\n        \n        # Object to describe the result\n        results = cross_val_score(estimator, X, Y, cv = kfold)\n        # Result\n        print(\"Result: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n        \n    def getProbs(self, x):\n        return self.model.predictProba(x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Extracting features from the Audio using a spectrogram"},{"metadata":{},"cell_type":"markdown","source":"This function loads each audio clip, predicts the birds that sing in it, and turns this into a df."},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_predictions(test_df, model, path):\n    unique_audio_id = test_df.audio_id.unique()\n    preds = []\n    for audio_id in unique_audio_id:\n        try:\n            clip, _ = librosa.load(test_audio / (audio_id + \".mp3\"),\n                                   sr=TARGET_SR,\n                                   mono=True,\n                                   res_type=\"kaiser_fast\")\n        \n            test_df_for_audio_id = test_df.query(f\"audio_id == '{audio_id}'\").reset_index(drop=True)\n            prediction_dict = predict_clip(clip, model, test_df_for_audio_id)\n            row_id = list(prediction_dict.keys())\n            birds = list(prediction_dict.values())\n            prediction_df = pd.DataFrame({\n                \"row_id\": row_id,\n                \"birds\": birds\n            })\n            preds.append(prediction_df)\n        except Exception as e:\n            print(e)\n    # Convert into a Panda dataframe \n    prediction_df = pd.concat(preds, axis=0, sort=False).reset_index(drop=True)\n    return prediction_df\n            ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Loading"},{"metadata":{"trusted":true},"cell_type":"code","source":"from pathlib import Path\n\nTARGET_SR = 32000\nTEST = Path(\"../input/birdsong-recognition/test_audio\").exists()\n\nif TEST:\n    DATA_DIR = Path(\"../input/birdsong-recognition/\")\nelse:\n    # dataset created by @shonenkov, thanks!\n    DATA_DIR = Path(\"../input/birdcall-check/\")\n    \n\ntest = pd.read_csv(DATA_DIR / \"test.csv\")\ntest_audio = DATA_DIR / \"test_audio\"\n\n\n#test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv(\"../input/birdsong-recognition/sample_submission.csv\")\nsub.to_csv(\"submission.csv\", index=False)  # this will be overwritten if everything goes well","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is a wrapper class for the dataset to return snippets of the clips along with their row id and site."},{"metadata":{"trusted":true},"cell_type":"code","source":"class TestDataset(data.Dataset):\n    def __init__(self, df: pd.DataFrame, clip: np.ndarray, SR=32000):\n        self.df = df\n        self.clip = clip\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx: int):\n        sample = self.df.loc[idx, :]\n        site = sample.site\n        row_id = sample.row_id\n        \n        end_seconds = int(sample.seconds)\n        start_seconds = int(end_seconds - 5)\n            \n        start_index = SR * start_seconds\n        end_index = SR * end_seconds\n            \n        snippet = self.clip[start_index:end_index].astype(np.float32)\n        \n        return snippet, row_id, site","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This function predicts a single clip by iterating over the snippets and their row_ids belonging to this clip. It creates an mfcc for each snippet and predicts it, creating a corresponding label."},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_clip(clip: np.ndarray, model: SeqModel, test_df, threshold=0.5):\n    prediction_dict = {}\n    \n    dataset = TestDataset(df=test_df, \n                          clip=clip)\n    loader = data.DataLoader(dataset, batch_size=1, shuffle=False)\n    \n    for snippet, row_id, site in progress_bar(loader):\n        site = site[0]  # use for prediction?\n        row_id = row_id[0]\n        mfccs = librosa.feature.mfcc(y=cur_audio, sr=32000, n_mfcc=40) #[0:66150]\n        probs = model.getProbs(mfccs)\n        probs = probs.detach().cpu().numpy().reshape(-1)\n        events = proba >= threshold\n        labels = np.argwhere(events).reshape(-1).tolist()\n        \n        if len(labels) == 0:\n            prediction_dict[row_id] = \"nocall\"\n        else:\n            labels_str_list = list(map(lambda x: INV_BIRD_CODE[x], labels))\n            label_string = \" \".join(labels_str_list)\n            prediction_dict[row_id] = label_string\n    return prediction_dict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Function to init the model and call get_predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def prediction(test_df: pd.DataFrame,\n               test_audio: Path,\n               threshold=0.5):\n    model = SeqModel(weights_path=\"../input/birdcall-weights/best.pth\")\n    return get_predictions(test_df, model, test_audio)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = prediction(test_df=test,\n                        test_audio=test_audio,\n                        threshold=0.8)\nsubmission.to_csv(\"submission.csv\", index=False)\n\nsubmission","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}